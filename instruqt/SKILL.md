# Instruqt — Interactive Lab Platform

## What Is Instruqt?
Instruqt is a platform for creating browser-based, hands-on labs with real infrastructure (VMs, containers, cloud accounts). Learners interact via terminals, code editors, web apps, and virtual browsers — all in-browser.

**Docs:** https://docs.instruqt.com/

---

## Core Concepts

### Track
A track is a complete lab experience. It contains:
- **Metadata** (`track.yml`) — title, slug, description, time limits
- **Sandbox config** (`config.yml`) — VMs, containers, cloud accounts
- **Challenges** — ordered steps the learner completes
- **Lifecycle scripts** — automation that runs at track/challenge boundaries

### Challenge
A step within a track. Each challenge has:
- `assignment.md` — YAML frontmatter + markdown instructions shown to the learner
- Lifecycle scripts: `setup-<host>`, `check-<host>`, `solve-<host>`, `cleanup-<host>`
- Tabs configuration (terminals, editors, web services, virtual browsers)

### Sandbox
The infrastructure backing a track. Can contain:
- **Virtual machines** (Linux/Windows, custom GCP images)
- **Containers** (lightweight, fast to deploy)
- **Virtual browsers** (website service hosts)
- **Cloud accounts** (GCP projects, AWS accounts, Azure subscriptions)
- **Custom resources** (Terraform modules)

---

## Directory Structure

```
my-track/
├── track.yml                    # Track metadata
├── config.yml                   # Sandbox definition
├── track_scripts/               # Track-level lifecycle scripts
│   ├── setup-<hostname>
│   └── cleanup-<hostname>
├── 01-first-challenge/          # Challenge directories (ordered by prefix)
│   ├── assignment.md            # Challenge config + assignment text
│   ├── setup-<hostname>
│   ├── check-<hostname>
│   ├── solve-<hostname>
│   └── cleanup-<hostname>
└── 02-second-challenge/
    ├── assignment.md
    ├── setup-<hostname>
    ├── check-<hostname>
    └── solve-<hostname>
```

---

## Configuration Files

### track.yml
```yaml
slug: my-track-slug
id: <auto-generated>
type: track
title: My Track Title
teaser: Short one-line teaser for listing pages
description: |-
  Multi-line description of what learners will accomplish.
icon: https://cdn.instruqt.com/assets/templates/ubuntu.png
tags:
- kubernetes
- networking
owner: my-team-slug
developers:
- developer@example.com
maintenance: true
show_timer: true
skipping_enabled: true
timelimit: 3600          # seconds (required)
idle_timeout: 600        # seconds (optional but recommended)
extend_ttl: 900          # seconds users can self-extend
lab_config:
  sidebar_enabled: true
  feedback_recap_enabled: true
  feedback_tab_enabled: true
  loadingMessages: true
  theme:
    name: modern-dark     # or "original"
  default_layout: AssignmentRight  # AssignmentLeft, AssignmentBottom
  default_layout_sidebar_size: 35  # 25-100
  override_challenge_layout: false
```

### config.yml
```yaml
version: "3"

# Containers (fast, lightweight)
containers:
- name: workstation
  image: gcr.io/instruqt/ubuntu-2204
  shell: /bin/bash
  memory: 2048

# Virtual machines (more control, external access)
virtualmachines:
- name: k8s-node
  image: my-gcp-project/my-custom-image
  shell: /bin/bash
  machine_type: n1-standard-4

# Virtual browser hosts
virtualbrowsers:
- name: web-app
  url: https://example.com

# Cloud accounts
gcp_projects:
- name: my-gcp
  services:
  - container.googleapis.com
  - compute.googleapis.com
  roles:
  - roles/container.admin
  - roles/compute.admin

aws_accounts:
- name: my-aws
  managed_policies:
  - arn:aws:iam::aws:policy/AdministratorAccess

azure_subscriptions:
- name: my-azure
  roles:
  - Contributor

# Secrets (team-level, referenced by name)
secrets:
- name: MY_API_KEY
- name: LICENSE_KEY
```

### assignment.md (per challenge)
```markdown
---
slug: deploy-the-app
id: <auto-generated>
type: challenge
title: Deploy the Application
teaser: Deploy and verify the application is running
notes:
- type: text
  contents: |-
    # Welcome!
    In this challenge you'll deploy the app to your cluster.
- type: image
  url: https://example.com/diagram.png
tabs:
- title: Terminal
  type: terminal
  hostname: workstation
- title: Code Editor
  type: code
  hostname: workstation
  path: /root/app
- title: App UI
  type: service
  hostname: workstation
  port: 8080
- title: Docs
  type: website
  url: https://docs.example.com
  new_window: false
difficulty: basic        # basic, intermediate, advanced
timelimit: 900           # per-challenge time limit in seconds
enhanced_loading: false
---

# Deploy the Application

In this challenge, you'll deploy the application to your Kubernetes cluster.

## Step 1: Apply the manifest
Run the following command in the **Terminal** tab:

```bash
kubectl apply -f /root/app/deploy.yaml
```

## Step 2: Verify
Check that the pods are running:

```bash
kubectl get pods -n default
```

You should see the `my-app` pod in `Running` state.
```

---

## Tab Types

| Type | YAML `type` | Key Fields |
|------|------------|------------|
| Terminal | `terminal` | `hostname`, `workdir`, `cmd` |
| Code Editor | `code` | `hostname`, `path` |
| Your App (service) | `service` | `hostname`, `port`, `path`, `protocol` |
| Website | `website` | `url`, `new_window` |
| Virtual Browser | `browser` | `hostname` (must be a website service host) |

---

## Lifecycle Scripts

### Execution Order
1. **Track setup** (`track_scripts/setup-<host>`) — runs once when sandbox starts
2. For each challenge:
   a. **Challenge setup** (`<challenge>/setup-<host>`)
   b. *Learner interacts*
   c. **Challenge check** (`<challenge>/check-<host>`) — on "Check" click
   d. **Challenge cleanup** (`<challenge>/cleanup-<host>`) — async after completion
3. **Track cleanup** (`track_scripts/cleanup-<host>`) — after track ends

### Script Naming
Scripts follow `<type>-<hostname>` format. If your host is `workstation`:
- `setup-workstation`
- `check-workstation`
- `solve-workstation`
- `cleanup-workstation`

Scripts run in alphanumeric hostname order (e.g., `host-a` before `host-b`).

### Script Timeouts
| Script | Timeout |
|--------|---------|
| Track setup/cleanup | 55 min |
| Challenge setup/solve/cleanup | 55 min |
| Challenge check | **1 min** |

### Essential Patterns

**Always start scripts with:**
```bash
#!/bin/bash
set -euxo pipefail
```

**Wait for bootstrap in track setup:**
```bash
while [ ! -f /opt/instruqt/bootstrap/host-bootstrap-completed ]; do
    echo "Waiting for Instruqt to finish booting the VM"
    sleep 1
done
```

**Check script with fail-message:**
```bash
#!/bin/bash
set -euxo pipefail

if ! kubectl get deployment my-app -n default &>/dev/null; then
    fail-message "Deployment 'my-app' not found. Did you run kubectl apply?"
fi

READY=$(kubectl get deployment my-app -n default -o jsonpath='{.status.readyReplicas}' 2>/dev/null)
if [ "$READY" != "1" ]; then
    fail-message "Deployment exists but pods aren't ready yet. Check pod status with 'kubectl get pods'."
fi
```

**Solve script (mirrors what the user should do):**
```bash
#!/bin/bash
set -euxo pipefail

kubectl apply -f /root/app/deploy.yaml
kubectl rollout status deployment/my-app -n default --timeout=120s
```

### Available Environment Variables in Scripts
| Variable | Description |
|----------|-------------|
| `INSTRUQT_TRACK_ID` | Track ID |
| `INSTRUQT_TRACK_SLUG` | Track slug |
| `INSTRUQT_CHALLENGE_ID` | Challenge ID (empty in track scripts) |
| `INSTRUQT_PARTICIPANT_ID` | Unique per play |
| `INSTRUQT_USER_ID` | User ID (empty in hot start track setup) |
| `INSTRUQT_USER_NAME` | User name (requires consent) |
| `INSTRUQT_USER_EMAIL` | User email (requires consent) |
| `INSTRUQT_TRACK_INVITE_ID` | Invite ID if accessed via invite |

### Helper Scripts (injected by Instruqt)
- `fail-message "text"` — sends failure feedback to learner (prefixes `FAIL:`)
- `set-workdir <dir>` — changes terminal working directory for the challenge

### Runtime Variables (cross-host, cross-challenge state)
```bash
# Set a variable (in a lifecycle script)
agent variable set MY_KEY my_value

# Get a variable
agent variable get MY_KEY
```

Use in assignment markdown:
```
[[ Instruqt-Var key="MY_KEY" hostname="workstation" ]]
```

---

## CLI Commands

### Setup
```bash
# Install CLI (see docs.instruqt.com/getting-started)
# Login
instruqt auth login

# Set default team
instruqt config set team my-team-slug
```

### Track Operations
```bash
# Create new track (interactive)
instruqt track create

# Create from existing
instruqt track create --title "My Track" --from team/existing-track-slug

# Pull remote track to local
instruqt track pull my-track-slug
# or with team prefix
instruqt track pull my-team/my-track-slug

# Push local changes
instruqt track push
instruqt track push --force   # overwrite remote

# Validate locally
instruqt track validate

# Open in browser
instruqt track open
```

### Challenge Operations
```bash
# Create challenge (run inside track directory)
instruqt challenge create --title "Install the CLI"
```

### Testing
```bash
# Full test (setup → check-fail → solve → check-pass for each challenge)
instruqt track test

# Skip initial check-fail step
instruqt track test --skip-fail-check

# Keep sandbox running after test (inspect at play.instruqt.com)
instruqt track test --keep-running

# With runtime parameters
instruqt track test --runtime-parameters=USER_ID=testuser --runtime-secrets=API_KEY=SECRET_API_KEY
```

### Logs
```bash
instruqt track logs --since 30m
instruqt track logs --participant-id <ID> --severity DEBUG
```

### Secrets
```bash
instruqt secrets list
instruqt secrets create MY_SECRET "value" --description="API key for X"
instruqt secrets update MY_SECRET "new-value"
instruqt secrets delete MY_SECRET
```

### CI/CD
- Set `INSTRUQT_TOKEN` env var with API token
- Use Docker image `instruqt/cli` in pipelines

---

## Secrets

Secrets are team-level, write-only sensitive values. Workflow:
1. Create secret: `instruqt secrets create MY_KEY "value"`
2. Reference in `config.yml`: `secrets: [{name: MY_KEY}]`
3. Use in scripts as `$MY_KEY` environment variable

---

## Runtime Parameters

Inject values at play time via embed URLs, invites, or API:

**Embed URL:**
```
https://play.instruqt.com/embed/TEAM/tracks/TRACK?token=TOKEN&rtp_USER_ID=bob&rts_API_KEY=SECRET_NAME
```

- `rtp_<name>=<value>` — plain text parameter
- `rts_<name>=<secret_name>` — secret reference

**Note:** Runtime parameters are NOT available in hot start track setup scripts. Use first challenge setup instead.

---

## Hot Start

Pre-provision sandbox pools for instant access:
- **Always hot** — maintains N ready sandboxes continuously
- **Scheduled** — provisions at a specific date/time with TTL
- **Invite-linked** — auto-syncs with a track invite

**Best practices:**
- Start with 1-2 instances, increase if users experience delays
- Put heavy setup in track setup scripts (they run during pre-provisioning)
- Keep first challenge setup script minimal (it runs on-demand)
- Add health checks at end of track setup scripts
- Schedule pools ~1 hour before events
- Terminate pools 15-30 min after session starts to save costs
- `INSTRUQT_USER_*` variables are empty in hot start track setup scripts

---

## Embedding & Sharing

### iframe Embed
```html
<iframe
  width="1140" height="640"
  sandbox="allow-forms allow-modals allow-popups allow-same-origin allow-scripts allow-popups-to-escape-sandbox"
  src="https://play.instruqt.com/embed/TEAM/tracks/TRACK?token=em_TOKEN"
  style="border: 0;"
  allowfullscreen>
</iframe>
```

### Kiosk Mode
Direct full-screen link: same URL format, shared as a link.

### URL Parameters
- `showChallenges=true` — show challenge list on splash
- `finish_btn_text=...&finish_btn_url=...` — CTA on finish
- `finish_text=...` — custom finish message
- `disable_feedback=true` — skip feedback
- `icp_<name>=<value>` — custom tracking parameters (propagated to webhooks/analytics)

### Event Callbacks (postMessage)
| Event | When |
|-------|------|
| `track.started` | User clicks Launch |
| `track.ready` | Sandbox ready |
| `track.challenge_started` | Challenge begins |
| `track.challenge_skipped` | Challenge skipped |
| `track.challenge_completed` | Challenge completed |
| `track.completed` | Track finished |

---

## Custom Resources

Import Terraform Registry modules as sandbox resources. Outputs are injected as environment variables prefixed with the resource name.

Example: Resource named `sqldb` with output `ENDPOINT` → `$SQLDB_ENDPOINT` in lifecycle scripts.

---

## Best Practices for Engaging Labs

### Track Design
1. **5-15 min ideal length** for demos; up to 60 min for workshops
2. **3-7 challenges** per track — each focused on one concept
3. **Progressive complexity** — easy first challenge builds confidence
4. Start each challenge assignment with context, then clear numbered steps
5. Use notes (in assignment.md frontmatter) for pre-challenge context/diagrams

### Performance
1. **Use custom VM images** — bake in large downloads/installations to cut setup time
2. **Move heavy work to track setup** — not challenge setup (especially with hot start)
3. **Wait for bootstrap** in track setup scripts
4. Containers are faster to provision than VMs when you don't need full VM features

### Scripting
1. Always `set -euxo pipefail` at the top
2. Write `solve` scripts for every challenge — enables skip functionality AND `instruqt track test`
3. Check scripts should give helpful, specific `fail-message` feedback
4. Keep check scripts fast (1 min timeout!)
5. Use `agent variable set/get` to pass state between challenges

### Content
1. Use emojis and formatting to make assignments scannable
2. Include "verify" steps so learners confirm their work before clicking Check
3. Use code blocks with syntax highlighting for all commands
4. Add tab references: "Switch to the **Terminal** tab"

---

## Patterns for Solo.io / Cloud-Native Tracks

### Kubernetes + Gateway API Track
```yaml
# config.yml
version: "3"
containers:
- name: workstation
  image: gcr.io/instruqt/ubuntu-2204
  shell: /bin/bash
  memory: 4096
```

**Track setup pattern (`track_scripts/setup-workstation`):**
```bash
#!/bin/bash
set -euxo pipefail

while [ ! -f /opt/instruqt/bootstrap/host-bootstrap-completed ]; do
    sleep 1
done

# Install tools
snap install kubectl --classic
snap install helm --classic
curl -sL https://kind.sigs.k8s.io/dl/latest/linux-amd64 -o /usr/local/bin/kind && chmod +x /usr/local/bin/kind

# Create kind cluster
cat <<EOF | kind create cluster --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
  - containerPort: 443
    hostPort: 443
EOF

# Install Gateway API CRDs
kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/latest/download/standard-install.yaml

# Install product (e.g., kgateway, AgentGateway)
helm repo add solo https://storage.googleapis.com/solo-public-helm
helm repo update
# helm install ...

# Health check
kubectl wait --for=condition=Ready pods --all -n kube-system --timeout=120s

echo "Track setup complete"
```

### Multi-tab Challenge for API Gateway Demo
```yaml
# In assignment.md frontmatter
tabs:
- title: Terminal
  type: terminal
  hostname: workstation
- title: Code Editor
  type: code
  hostname: workstation
  path: /root/lab
- title: Gateway UI
  type: service
  hostname: workstation
  port: 8080
- title: API Testing
  type: terminal
  hostname: workstation
  workdir: /root/lab
```
